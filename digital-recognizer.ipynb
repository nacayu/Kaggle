{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch \nfrom torch import nn\nfrom torch.utils.data import TensorDataset, DataLoader\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms as tfs\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-21T15:22:44.259890Z","iopub.execute_input":"2022-02-21T15:22:44.260380Z","iopub.status.idle":"2022-02-21T15:22:44.265678Z","shell.execute_reply.started":"2022-02-21T15:22:44.260347Z","shell.execute_reply":"2022-02-21T15:22:44.265078Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')\ny, x= data.iloc[:, 0], data.iloc[:, 1:]\n\ntest = torch.from_numpy(np.array(test).astype(np.float32))\n\nx, y = np.array(x), np.array(y)\nx_copy = x\ny_copy = y\nx, x_vl, y, y_vl = train_test_split(x, y, test_size = 0.3, shuffle = True)\n\nx, y, x_vl, y_vl = torch.from_numpy(x.astype(np.float32)), torch.from_numpy(y.astype(np.float32)), torch.from_numpy(x_vl.astype(np.float32)), torch.from_numpy(y_vl.astype(np.float32))\nx = x.view(-1, 1, 28, 28)\nx_vl = x_vl.view(-1, 1, 28, 28)\ntest = test.view(-1, 1, 28, 28)\nprint(x.shape, x_vl.shape, test.shape, y.shape)\nx_copy.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:22:44.267174Z","iopub.execute_input":"2022-02-21T15:22:44.267635Z","iopub.status.idle":"2022-02-21T15:22:49.241028Z","shell.execute_reply.started":"2022-02-21T15:22:44.267601Z","shell.execute_reply":"2022-02-21T15:22:49.240231Z"},"trusted":true},"execution_count":156,"outputs":[{"name":"stdout","text":"torch.Size([29400, 1, 28, 28]) torch.Size([12600, 1, 28, 28]) torch.Size([28000, 1, 28, 28]) torch.Size([29400])\n","output_type":"stream"},{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"(42000, 784)"},"metadata":{}}]},{"cell_type":"code","source":"im_aug = tfs.Compose([\n    tfs.Resize(32),\n    tfs.RandomHorizontalFlip(),\n    tfs.RandomCrop(28),\n    tfs.ColorJitter(contrast=1),\n    tfs.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:22:49.242293Z","iopub.execute_input":"2022-02-21T15:22:49.242523Z","iopub.status.idle":"2022-02-21T15:22:49.247764Z","shell.execute_reply.started":"2022-02-21T15:22:49.242495Z","shell.execute_reply":"2022-02-21T15:22:49.246767Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"x_copy = x_copy.reshape(-1, 28, 28)\nx_aug = torch.tensor(x_copy)\nfor idx, _ in enumerate(x_copy):\n    x_aug[idx] = im_aug(Image.fromarray(np.uint8(x_copy[idx])))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:22:49.249473Z","iopub.execute_input":"2022-02-21T15:22:49.249699Z","iopub.status.idle":"2022-02-21T15:23:10.190892Z","shell.execute_reply.started":"2022-02-21T15:22:49.249672Z","shell.execute_reply":"2022-02-21T15:23:10.190032Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"x_aug = x_aug.reshape(-1, 1, 28, 28)\nprint(x.shape, x_aug.shape)\nx = torch.cat((x, x_aug), 0)\nx = x.float()\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:23:10.192233Z","iopub.execute_input":"2022-02-21T15:23:10.192445Z","iopub.status.idle":"2022-02-21T15:23:10.441077Z","shell.execute_reply.started":"2022-02-21T15:23:10.192419Z","shell.execute_reply":"2022-02-21T15:23:10.440329Z"},"trusted":true},"execution_count":159,"outputs":[{"name":"stdout","text":"torch.Size([29400, 1, 28, 28]) torch.Size([42000, 1, 28, 28])\ntorch.Size([71400, 1, 28, 28])\n","output_type":"stream"}]},{"cell_type":"code","source":"y_aug = torch.tensor(y_copy)\ny = torch.cat((y, y_aug))\nx = x.float()\ny = y.long()\nprint(x.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:23:10.443329Z","iopub.execute_input":"2022-02-21T15:23:10.444174Z","iopub.status.idle":"2022-02-21T15:23:10.451303Z","shell.execute_reply.started":"2022-02-21T15:23:10.444130Z","shell.execute_reply":"2022-02-21T15:23:10.450396Z"},"trusted":true},"execution_count":160,"outputs":[{"name":"stdout","text":"torch.Size([71400, 1, 28, 28]) torch.Size([71400])\n","output_type":"stream"}]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv = nn.Sequential( \n            # size: 28*28\n            nn.Conv2d(1,8,3,1,1), # in_channels out_channels kernel_size stride padding\n            nn.BatchNorm2d(8),\n            nn.ReLU(),\n            nn.Conv2d(8,16,3,1,1), \n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            # size: 14*14\n            nn.Conv2d(16,16,3,1,1), \n            nn.ReLU(),\n            nn.Conv2d(16,8,3,1,1), \n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.fc = nn.Sequential(\n            # size: 7*7\n            nn.Linear(8*7*7,256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256,256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256,10)\n        )\n\n    \n    def forward(self, img):\n        x = self.conv(img)\n        o = self.fc(x.view(x.shape[0],-1))\n        return o\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:23:10.452612Z","iopub.execute_input":"2022-02-21T15:23:10.452838Z","iopub.status.idle":"2022-02-21T15:23:10.464740Z","shell.execute_reply.started":"2022-02-21T15:23:10.452811Z","shell.execute_reply":"2022-02-21T15:23:10.463819Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"bs = 64\ntrainDS = TensorDataset(x, y)\ntestDS = TensorDataset(test)\nvalidDS = TensorDataset(x_vl, y_vl)\n\ntrainDL = DataLoader(trainDS, batch_size = bs, shuffle = True)\ntestDL = DataLoader(testDS, batch_size = bs, shuffle = True)\nvalidDL = DataLoader(validDS, batch_size = bs, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:23:10.466081Z","iopub.execute_input":"2022-02-21T15:23:10.466375Z","iopub.status.idle":"2022-02-21T15:23:10.480284Z","shell.execute_reply.started":"2022-02-21T15:23:10.466336Z","shell.execute_reply":"2022-02-21T15:23:10.479402Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nnet = Net()\noptim = torch.optim.SGD(net.parameters(), lr = 0.01)\nepochs = 22","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:23:10.481597Z","iopub.execute_input":"2022-02-21T15:23:10.481898Z","iopub.status.idle":"2022-02-21T15:23:10.501571Z","shell.execute_reply.started":"2022-02-21T15:23:10.481858Z","shell.execute_reply":"2022-02-21T15:23:10.500591Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    epoc_train_loss = 0.0\n    epoc_train_corr = 0.0\n    epoc_valid_corr = 0.0\n    print('Epoch:{}/{}'.format(epoch,epochs))\n    \n    for data in trainDL:\n        \n        images,labels = data\n        outputs = net(images)               \n        optim.zero_grad()\n        loss = criterion(outputs,labels.long())\n        loss.backward()\n        optim.step()\n        \n        epoc_train_loss += loss.item()\n        outputs = torch.max(outputs,1)[1]\n        epoc_train_corr += torch.sum(outputs==labels)\n    \n    with torch.no_grad():\n        for data in validDL:\n\n            images,labels = data\n            labels = labels\n\n\n            outputs = net(images)\n            outputs = torch.max(outputs.data,1)[1]\n\n            epoc_valid_corr += torch.sum(outputs==labels.data)\n    \n    \n    print(\"loss is :{:.4f},Train Accuracy is:{:.4f}%,Test Accuracy is:{:.4f}%\".format(epoc_train_loss/len(trainDS),100*epoc_train_corr/len(trainDS),100*epoc_valid_corr/len(validDS)))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:23:10.504460Z","iopub.execute_input":"2022-02-21T15:23:10.505163Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch:0/22\nloss is :0.0322,Train Accuracy is:22.2367%,Test Accuracy is:76.3968%\nEpoch:1/22\nloss is :0.0247,Train Accuracy is:40.5308%,Test Accuracy is:86.8730%\nEpoch:2/22\nloss is :0.0235,Train Accuracy is:43.8599%,Test Accuracy is:89.6190%\nEpoch:3/22\nloss is :0.0226,Train Accuracy is:48.3725%,Test Accuracy is:88.6905%\nEpoch:4/22\nloss is :0.0210,Train Accuracy is:52.7479%,Test Accuracy is:87.9444%\nEpoch:5/22\nloss is :0.0194,Train Accuracy is:56.2423%,Test Accuracy is:88.8016%\nEpoch:6/22\nloss is :0.0180,Train Accuracy is:58.5868%,Test Accuracy is:91.2619%\nEpoch:7/22\nloss is :0.0170,Train Accuracy is:60.4888%,Test Accuracy is:90.5873%\nEpoch:8/22\nloss is :0.0164,Train Accuracy is:61.5182%,Test Accuracy is:91.0159%\nEpoch:9/22\nloss is :0.0160,Train Accuracy is:62.6443%,Test Accuracy is:91.2778%\nEpoch:10/22\nloss is :0.0156,Train Accuracy is:63.3193%,Test Accuracy is:92.1825%\nEpoch:11/22\nloss is :0.0154,Train Accuracy is:63.6471%,Test Accuracy is:93.0079%\nEpoch:12/22\nloss is :0.0150,Train Accuracy is:64.5938%,Test Accuracy is:90.9444%\nEpoch:13/22\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = net(test)\ny_pred = torch.max(y_pred, 1)[1]\nprint(y_pred.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = np.array(y_pred)\nout = {'ImageId': range(1, len(out) + 1), 'Label': out}\nout = pd.DataFrame(out)\nprint(out.shape)\nout.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}